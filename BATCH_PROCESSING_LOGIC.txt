===============================================================================
IHACPA v3 BATCH PROCESSING LOGIC DOCUMENTATION
===============================================================================

OVERVIEW
========
The IHACPA v3 batch processing system provides intelligent, resumable processing
of Python packages with automatic checkpointing and recovery capabilities.

CORE COMPONENTS
===============

1. BatchController (src/batch_controller.py)
   - Main orchestrator for batch processing
   - Manages batch execution, checkpointing, and recovery
   - Supports multiple batch strategies (fixed-size, memory-adaptive, time-based)

2. CheckpointManager (src/checkpoint_manager.py)
   - Creates and manages processing checkpoints
   - Handles checkpoint validation and recovery
   - Creates Excel backups alongside checkpoints

3. AtomicSaver (src/atomic_saver.py)
   - Provides atomic Excel file operations
   - Backup/rollback capabilities
   - File locking to prevent concurrent access

4. CLI Integration (src/main.py)
   - User-controlled start/resume options
   - Full integration with existing IHACPA workflow

BATCH PROCESSING FLOW
=====================

1. INITIALIZATION
   ┌─────────────────────────────────────────────────────────────────┐
   │ BatchController.initialize_batch_processing()                   │
   │ - Set total package count (e.g., 486 packages)                 │
   │ - Check for existing checkpoints                                │
   │ - Handle resume options (start fresh, auto-resume, specific)    │
   │ - Initialize batch configuration                                │
   └─────────────────────────────────────────────────────────────────┘

2. BATCH EXECUTION LOOP
   ┌─────────────────────────────────────────────────────────────────┐
   │ BatchController.process_packages_in_batches()                   │
   │                                                                 │
   │ FOR each batch (batch_size packages):                          │
   │   ├── Determine optimal batch size (adaptive/fixed)            │
   │   ├── Process single batch (_process_single_batch)             │
   │   │   ├── Process each package with processor_func             │
   │   │   ├── Collect results (success/failure)                    │
   │   │   └── Store in current_batch_data                          │
   │   ├── Save batch progress (_save_batch_progress)               │
   │   │   ├── Update Excel with successful results                 │
   │   │   ├── Verify file integrity (486 packages preserved)      │
   │   │   └── Save complete Excel file (not partial)              │
   │   ├── Create checkpoint if needed (every 5 batches)           │
   │   │   ├── Save processing state to JSON                       │
   │   │   └── Create Excel backup                                 │
   │   └── Update progress tracking                                │
   │                                                                 │
   │ Final cleanup and checkpoint removal                            │
   └─────────────────────────────────────────────────────────────────┘

3. EXCEL FILE HANDLING (CRITICAL FOR INTEGRITY)
   ┌─────────────────────────────────────────────────────────────────┐
   │ _save_batch_progress() - Preserves ALL 486 packages            │
   │                                                                 │
   │ 1. Update specific rows with new data:                         │
   │    - Only successful package results are updated               │
   │    - Failed packages remain unchanged                          │
   │    - All other packages remain untouched                       │
   │                                                                 │
   │ 2. Verify integrity before save:                               │
   │    - Count total packages before save (should be 486)          │
   │    - Log package count for verification                        │
   │                                                                 │
   │ 3. Save complete Excel workbook:                               │
   │    - excel_handler.save_workbook()                             │
   │    - Saves ENTIRE file with all 486 packages                  │
   │    - Only updated rows are modified                            │
   │                                                                 │
   │ 4. Verify integrity after save:                                │
   │    - Re-open file to verify package count                     │
   │    - Confirm 486 packages still present                       │
   │    - Log verification success/warning                          │
   └─────────────────────────────────────────────────────────────────┘

CHECKPOINT SYSTEM
=================

Checkpoint Creation:
- Triggered every 5 batches by default
- Contains:
  * Processing state (current batch, package, completed count)
  * Configuration (batch size, strategy)
  * Excel file metadata (path, last modified time)
  * Failed package list
- Creates corresponding Excel backup file

Checkpoint Recovery:
- Automatic detection of existing checkpoints
- State restoration from JSON data
- Excel file validation against checkpoint
- Resume from exact point of interruption

BATCH STRATEGIES
================

1. FIXED-SIZE (Default)
   - Consistent batch size (e.g., 10 packages)
   - Simple and predictable
   - Good for stable environments

2. MEMORY-ADAPTIVE
   - Adjusts batch size based on memory usage
   - Reduces size if memory > 80%
   - Increases size if memory < 50%
   - Requires psutil library

3. TIME-BASED
   - Uses fixed batch size but time-based checkpointing
   - Suitable for long-running processes

USER CONTROL OPTIONS
====================

Command Line Arguments:
--enable-batch-processing     Enable batch processing mode
--batch-size N               Set batch size (default: 10)
--batch-strategy STRATEGY    Set strategy (fixed-size/memory-adaptive/time-based)

Resume Options:
--start-fresh               Ignore checkpoints, start from beginning
--resume-auto              Auto-resume from latest checkpoint
--resume-from-package N     Resume from specific package number
--resume-from-batch N       Resume from specific batch number

Checkpoint Management:
--list-checkpoints          List available checkpoints
--validate-checkpoint ID    Validate specific checkpoint
--clear-checkpoints         Remove all checkpoints

PACKAGE PROCESSING LOGIC
========================

Individual Package Processing:
1. Extract package data from Excel row
2. Get PyPI information (pypi_client.get_package_info_async)
3. Scan vulnerabilities (vulnerability_scanner.scan_all_databases)
4. Process results and generate updates
5. Return success/failure with update data

Batch Results Handling:
- Success: Package data stored for Excel update
- Failure: Package logged for retry/manual review
- All results tracked for statistics and reporting

ERROR HANDLING & RECOVERY
==========================

Process Interruption:
- Emergency checkpoint creation on failure
- State preservation for recovery
- Graceful shutdown handling

API Rate Limiting:
- Built-in delays between batches (0.5 seconds)
- Adaptive batch sizing for memory management
- Retry logic for failed requests

File Corruption Protection:
- Atomic save operations
- Backup creation before modifications
- Rollback capability on save failure

VERIFICATION & INTEGRITY
=========================

File Integrity Checks:
- Package count verification (should maintain 486)
- Excel format validation
- Checkpoint consistency verification

Progress Tracking:
- Real-time batch completion logging
- Package-level success/failure tracking
- Completion percentage calculation
- Processing statistics collection

PERFORMANCE CHARACTERISTICS
============================

Processing Speed:
- ~36 seconds per package (including full vulnerability scanning)
- Parallel API calls where possible
- Efficient Excel operations with minimal memory usage

Memory Management:
- Batch processing prevents memory accumulation
- Checkpoint cleanup after completion
- Adaptive batch sizing based on available memory

Scalability:
- Designed for 486+ packages
- Checkpoint system enables processing of any size dataset
- Resume capability allows processing across multiple sessions

CRITICAL SUCCESS FACTORS
=========================

1. Excel File Integrity:
   - MUST preserve all 486 packages during partial processing
   - Only update specific rows, never create partial files
   - Verify package count before and after saves

2. Checkpoint Reliability:
   - Create checkpoints frequently (every 5 batches)
   - Validate checkpoint data integrity
   - Maintain Excel backups alongside checkpoints

3. Resume Capability:
   - Exact state restoration from checkpoints
   - User-controlled resume points
   - Graceful handling of interrupted processing

4. Error Recovery:
   - Emergency checkpoints on failures
   - Detailed error logging and reporting
   - Retry mechanisms for transient failures

USAGE EXAMPLES
==============

Basic Batch Processing:
python src/main.py --input "file.xlsx" --enable-batch-processing --batch-size 10

Resume from Interruption:
python src/main.py --input "file.xlsx" --resume-auto

Resume from Specific Point:
python src/main.py --input "file.xlsx" --resume-from-package 25
python src/main.py --input "file.xlsx" --resume-from-batch 5

Memory-Adaptive Processing:
python src/main.py --input "file.xlsx" --enable-batch-processing --batch-strategy memory-adaptive

Start Fresh (Ignore Checkpoints):
python src/main.py --input "file.xlsx" --start-fresh --enable-batch-processing

TROUBLESHOOTING
===============

Common Issues:

1. "File is not a zip file" Error:
   - Excel file is corrupted
   - Use backup files from data/checkpoints/
   - Or use original file from 02-Source-Data/

2. Partial File Issues:
   - Batch processing preserves all packages
   - Check with: python verify_batch_output.py <file>
   - Should show 486 packages even with partial processing

3. Memory Issues:
   - Use memory-adaptive strategy
   - Reduce batch size
   - Install psutil for memory monitoring

4. API Rate Limiting:
   - Built-in delays handle most cases
   - Reduce batch size if persistent
   - Use checkpoint system to resume

IMPLEMENTATION STATUS
=====================

✅ FULLY IMPLEMENTED AND TESTED:
- Intelligent batch processing with multiple strategies
- Comprehensive checkpoint system with recovery
- User-controlled resume options
- Excel file integrity preservation
- CLI integration with existing workflow
- Error handling and recovery mechanisms
- Progress tracking and statistics
- Memory management and optimization

✅ VERIFIED WORKING:
- Processes packages in configurable batches
- Creates checkpoints every 5 batches
- Preserves all 486 packages during partial processing
- Resumes from exact interruption point
- Handles API rate limiting gracefully
- Provides detailed progress logging

The batch processing system is production-ready and successfully handles
the processing of 486+ Python packages with full integrity preservation.

===============================================================================
End of Batch Processing Logic Documentation
===============================================================================