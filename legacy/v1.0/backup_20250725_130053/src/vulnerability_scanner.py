#!/usr/bin/env python3
"""
Vulnerability Scanner for IHACPA Python Package Review Automation
Handles scanning multiple vulnerability databases for Python packages
Includes AI-powered CVE analysis using OpenAI API
"""

import asyncio
import aiohttp
import requests
import os
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import logging
import re
from urllib.parse import urljoin, quote

try:
    from .ai_cve_analyzer import AICVEAnalyzer
except ImportError:
    try:
        from ai_cve_analyzer import AICVEAnalyzer
    except ImportError:
        AICVEAnalyzer = None


class VulnerabilityScanner:
    """Scanner for checking multiple vulnerability databases"""
    
    DATABASES = {
        'nist_nvd': {
            'name': 'NIST NVD',
            'base_url': 'https://services.nvd.nist.gov/rest/json/cves/2.0',
            'search_param': 'keywordSearch',
            'enabled': True
        },
        'mitre_cve': {
            'name': 'MITRE CVE',
            'base_url': 'https://cve.mitre.org/cgi-bin/cvekey.cgi',
            'search_param': 'keyword',
            'enabled': True
        },
        'snyk': {
            'name': 'SNYK',
            'base_url': 'https://security.snyk.io/vuln/pip',
            'search_param': 'package',
            'enabled': True
        },
        'exploit_db': {
            'name': 'Exploit Database',
            'base_url': 'https://www.exploit-db.com/search',
            'search_param': 'text',
            'enabled': True
        },
        'github_advisory': {
            'name': 'GitHub Security Advisory',
            'base_url': 'https://github.com/advisories',
            'search_param': 'query',
            'enabled': True
        }
    }
    
    def __init__(self, timeout: int = 30, max_retries: int = 3, rate_limit: float = 1.0, 
                 openai_api_key: Optional[str] = None, ai_enabled: bool = True,
                 azure_endpoint: Optional[str] = None, azure_model: Optional[str] = None):
        """Initialize vulnerability scanner"""
        self.timeout = timeout
        self.max_retries = max_retries
        self.rate_limit = rate_limit  # Seconds between requests
        self.session = None
        self.logger = logging.getLogger(__name__)
        self.last_request_time = {}
        
        # Initialize AI CVE analyzer
        self.ai_analyzer = None
        if ai_enabled and AICVEAnalyzer:
            try:
                # Get API version from environment if not passed
                azure_api_version = os.getenv('AZURE_OPENAI_API_VERSION')
                
                # Use environment variables if parameters not provided
                if not azure_model:
                    azure_model = os.getenv('AZURE_OPENAI_MODEL')
                if not azure_endpoint:
                    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')
                if not openai_api_key:
                    openai_api_key = os.getenv('AZURE_OPENAI_KEY') or os.getenv('OPENAI_API_KEY')
                
                self.ai_analyzer = AICVEAnalyzer(
                    api_key=openai_api_key,
                    model=azure_model,
                    azure_endpoint=azure_endpoint,
                    api_version=azure_api_version
                )
                if self.ai_analyzer.is_enabled():
                    service_type = "Azure OpenAI" if self.ai_analyzer.is_azure else "Standard OpenAI"
                    self.logger.info(f"AI CVE analysis enabled using {service_type}")
                else:
                    self.logger.warning("AI CVE analysis disabled - configuration incomplete")
            except Exception as e:
                self.logger.error(f"Failed to initialize AI CVE analyzer: {e}")
                self.ai_analyzer = None
        else:
            self.logger.info("AI CVE analysis disabled")
        
    async def _rate_limited_request(self, database: str, url: str, params: Dict = None) -> Optional[Dict]:
        """Make rate-limited request with enhanced retry logic for API rate limits"""
        current_time = datetime.now()
        
        # Enhanced rate limiting for NIST NVD (more aggressive)
        rate_limit = 6 if database == 'nist_nvd' else self.rate_limit
        
        if database in self.last_request_time:
            time_since_last = (current_time - self.last_request_time[database]).total_seconds()
            if time_since_last < rate_limit:
                await asyncio.sleep(rate_limit - time_since_last)
        
        self.last_request_time[database] = current_time
        
        if not self.session:
            self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout))
        
        for attempt in range(self.max_retries):
            try:
                async with self.session.get(url, params=params) as response:
                    if response.status == 200:
                        return await response.json()
                    elif response.status == 404:
                        self.logger.debug(f"No data found for {url}")
                        return None
                    elif response.status == 429:
                        # Rate limiting - use exponential backoff with longer delays
                        backoff_time = (2 ** attempt) * 5  # 5, 10, 20, 40 seconds
                        self.logger.warning(f"HTTP 429 for {url}")
                        if attempt < self.max_retries - 1:
                            self.logger.info(f"Rate limited, waiting {backoff_time}s before retry {attempt + 2}")
                            await asyncio.sleep(backoff_time)
                            continue
                        else:
                            self.logger.error(f"Rate limiting persisted after {self.max_retries} attempts for {url}")
                            return None
                    elif response.status == 503:
                        # Service unavailable - temporary issue
                        backoff_time = (2 ** attempt) * 3  # 3, 6, 12, 24 seconds
                        self.logger.warning(f"HTTP 503 for {url}")
                        if attempt < self.max_retries - 1:
                            self.logger.info(f"Service unavailable, waiting {backoff_time}s before retry {attempt + 2}")
                            await asyncio.sleep(backoff_time)
                            continue
                        else:
                            return None
                    else:
                        self.logger.warning(f"HTTP {response.status} for {url}")
                        
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout on attempt {attempt + 1} for {url}")
                
            except aiohttp.ClientError as e:
                self.logger.error(f"Client error on attempt {attempt + 1} for {url}: {e}")
                
            except Exception as e:
                self.logger.error(f"Unexpected error for {url}: {e}")
                
            # Regular backoff for other errors
            if attempt < self.max_retries - 1:
                await asyncio.sleep(2 ** attempt)
                
        return None
    
    def _build_search_urls(self, package_name: str) -> Dict[str, str]:
        """Build search URLs for all databases"""
        urls = {}
        
        # NIST NVD
        urls['nist_nvd'] = f"{self.DATABASES['nist_nvd']['base_url']}?keywordSearch={quote(package_name)}"
        
        # MITRE CVE
        urls['mitre_cve'] = f"{self.DATABASES['mitre_cve']['base_url']}?keyword={quote(package_name)}"
        
        # SNYK
        urls['snyk'] = f"{self.DATABASES['snyk']['base_url']}/{quote(package_name)}"
        
        # Exploit Database
        urls['exploit_db'] = f"{self.DATABASES['exploit_db']['base_url']}?text={quote(package_name)}"
        
        # GitHub Security Advisory
        urls['github_advisory'] = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
        
        return urls
    
    async def scan_nist_nvd(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan NIST NVD database with proper API implementation based on real structure"""
        try:
            # Build proper NIST NVD API URL with enhanced search parameters
            base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            
            # Enhanced search strategies with priority for common package names
            search_urls = self._get_enhanced_search_urls(base_url, package_name)
            
            self.logger.debug(f"Scanning NIST NVD for {package_name} v{current_version}")
            
            all_results = []
            total_found = 0
            version_check_indeterminate = False
            
            # Try each search strategy with enhanced rate limiting
            successful_searches = 0
            max_searches = 8  # Limit total searches to avoid excessive rate limiting
            
            for i, search_url in enumerate(search_urls[:max_searches]):
                try:
                    # Progressive delay - longer delays for later searches
                    if i > 0:
                        delay = min(3 + i, 8)  # 3, 4, 5, 6, 7, 8 seconds max
                        await asyncio.sleep(delay)
                    
                    data = await self._rate_limited_request('nist_nvd', search_url)
                    
                    if data and data.get('vulnerabilities'):
                        successful_searches += 1
                        
                        for vuln in data['vulnerabilities']:
                            cve_data = vuln.get('cve', {})
                            cve_id = cve_data.get('id', '')
                            
                            # Skip if we already have this CVE
                            if any(r['cve_id'] == cve_id for r in all_results):
                                continue
                            
                            # Extract description for relevance check
                            descriptions = cve_data.get('descriptions', [])
                            description = descriptions[0].get('value', '') if descriptions else ''
                            
                            # Enhanced relevance check for Python packages
                            if self._is_python_cve_relevant_enhanced_nist(package_name, cve_id, description, cve_data):
                                # Get CVSS information
                                severity, score = self._extract_cvss_info(cve_data)
                                
                                # Check version impact with enhanced CPE parsing
                                version_impact_result = self._check_nist_version_impact(
                                    cve_data, current_version, package_name
                                )
                                
                                # Handle indeterminate version checking
                                if version_impact_result is None:
                                    version_check_indeterminate = True
                                    version_affected = False  # Default to False but track indeterminate state
                                else:
                                    version_affected = version_impact_result
                                
                                all_results.append({
                                    'cve_id': cve_id,
                                    'description': description[:300] + '...' if len(description) > 300 else description,
                                    'severity': severity,
                                    'score': score,
                                    'published': cve_data.get('published', '')[:10],  # Date only
                                    'modified': cve_data.get('lastModified', '')[:10],
                                    'version_affected': version_affected,
                                    'version_check_indeterminate': version_impact_result is None,
                                    'affected_configs': self._extract_affected_versions(cve_data, package_name)
                                })
                        
                        total_found += data.get('totalResults', 0)
                        
                        # If we're getting good results and have enough CVEs, consider stopping early
                        if len(all_results) >= 50 and successful_searches >= 3:
                            self.logger.debug(f"Early termination: Found {len(all_results)} CVEs from {successful_searches} successful searches")
                            break
                        
                    elif data is None:
                        # Request failed (likely rate limited) - reduce remaining searches
                        if successful_searches == 0 and i >= 2:
                            self.logger.warning(f"Multiple failures for {package_name}, stopping early to avoid rate limits")
                            break
                        
                except Exception as e:
                    self.logger.debug(f"Search strategy {i+1} failed: {e}")
                    continue
            
            # Sort by severity and date
            all_results.sort(key=lambda x: (
                self._severity_priority(x['severity']), 
                x['published']
            ), reverse=True)
            
            # Determine overall impact
            vulnerabilities_found = len(all_results) > 0
            affected_by_version = any(r.get('version_affected', False) for r in all_results)
            
            # Generate detailed summary
            summary = self._generate_nist_summary(
                all_results, current_version, affected_by_version, package_name, version_check_indeterminate
            )
            
            # Main URL for user reference
            primary_url = f"https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&query={quote(package_name)}"
            
            return {
                'database': 'NIST NVD',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': primary_url,
                'found_vulnerabilities': vulnerabilities_found,
                'vulnerability_count': len(all_results),
                'vulnerabilities': all_results,
                'summary': summary,
                'scanned_at': datetime.now().isoformat(),
                'version_affected': affected_by_version,
                'total_database_matches': total_found
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning NIST NVD for {package_name}: {e}")
            return self._error_result('nist_nvd', package_name, str(e))
    
    async def scan_mitre_cve(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Enhanced MITRE CVE database scanning with improved search strategy"""
        try:
            # MITRE CVE search URL (returns HTML that needs parsing)
            url = f"{self.DATABASES['mitre_cve']['base_url']}?keyword={quote(package_name)}"
            
            self.logger.debug(f"Scanning MITRE CVE for {package_name} v{current_version}")
            
            results = []
            
            # Enhanced search strategy - try multiple approaches to find CVEs
            nist_results = await self._get_enhanced_mitre_cve_data(package_name)
            
            version_check_indeterminate = False
            
            for cve_info in nist_results:
                # Enhanced relevance check specifically for MITRE CVE context
                if self._is_mitre_cve_relevant(package_name, cve_info):
                    # Check version impact
                    version_impact_result = self._check_mitre_version_impact(
                        cve_info, current_version, package_name
                    )
                    
                    # Handle indeterminate version checking
                    if version_impact_result is None:
                        version_check_indeterminate = True
                        version_affected = False  # Default to False but track indeterminate state
                    else:
                        version_affected = version_impact_result
                    
                    results.append({
                        'cve_id': cve_info['cve_id'],
                        'description': cve_info['description'][:300] + '...' if len(cve_info['description']) > 300 else cve_info['description'],
                        'severity': cve_info['severity'],
                        'score': cve_info['score'],
                        'published': cve_info['published'][:10],
                        'modified': cve_info['modified'][:10],
                        'version_affected': version_affected,
                        'version_check_indeterminate': version_impact_result is None,
                        'source': 'MITRE CVE (via NIST)'
                    })
            
            # Sort by severity and recency
            results.sort(key=lambda x: (
                self._severity_priority(x['severity']), 
                x['published']
            ), reverse=True)
            
            vulnerabilities_found = len(results) > 0
            affected_by_version = any(r.get('version_affected', False) for r in results)
            
            # Generate MITRE-specific summary
            summary = self._generate_mitre_summary(
                results, current_version, affected_by_version, package_name, version_check_indeterminate
            )
            
            return {
                'database': 'MITRE CVE',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': vulnerabilities_found,
                'vulnerability_count': len(results),
                'vulnerabilities': results,
                'summary': summary,
                'scanned_at': datetime.now().isoformat(),
                'version_affected': affected_by_version
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning MITRE CVE for {package_name}: {e}")
            return self._error_result('mitre_cve', package_name, str(e))
    
    async def scan_snyk(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan SNYK vulnerability database with proper interval notation parsing"""
        try:
            # Ensure session is initialized
            if not self.session:
                import aiohttp
                self.session = aiohttp.ClientSession()
            
            url = f"{self.DATABASES['snyk']['base_url']}/{quote(package_name)}"
            
            self.logger.debug(f"Scanning SNYK for {package_name} v{current_version}")
            
            # SNYK uses specific URL patterns and interval notation for version ranges
            results = []
            
            # Try to get SNYK vulnerability data through multiple approaches
            snyk_vulnerabilities = await self._fetch_snyk_vulnerabilities(package_name, url)
            
            for vuln_info in snyk_vulnerabilities:
                # Parse SNYK interval notation in AFFECTS column
                affected_ranges = vuln_info.get('affected_versions', [])
                version_affected = False
                
                if current_version and current_version != "NEW":
                    version_affected = self._parse_snyk_interval_notation(
                        current_version, affected_ranges
                    )
                
                results.append({
                    'id': vuln_info.get('id', f"SNYK-PYTHON-{package_name.upper()}-UNKNOWN"),
                    'vulnerability_id': vuln_info.get('id', f"SNYK-PYTHON-{package_name.upper()}-UNKNOWN"),
                    'title': vuln_info.get('title', 'Vulnerability found'),
                    'severity': vuln_info.get('severity', 'MEDIUM').upper(),
                    'affected_versions': affected_ranges,
                    'published': vuln_info.get('published_date', ''),
                    'related_cves': [],  # SNYK main page doesn't contain CVE info
                    'version_affected': version_affected,
                    'description': vuln_info.get('description', '')[:200]
                })
            
            # Sort by severity and date
            results.sort(key=lambda x: (
                self._severity_priority(x['severity']), 
                x['published']
            ), reverse=True)
            
            vulnerabilities_found = len(results) > 0
            affected_by_version = any(r.get('version_affected', False) for r in results)
            
            # Generate SNYK-specific summary using interval notation understanding
            summary = self._generate_snyk_summary(
                results, current_version, affected_by_version, package_name
            )
            
            return {
                'database': 'SNYK',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': vulnerabilities_found,
                'vulnerability_count': len(results),
                'vulnerabilities': results,
                'summary': summary,
                'scanned_at': datetime.now().isoformat(),
                'version_affected': affected_by_version
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning SNYK for {package_name}: {e}")
            return self._error_result('snyk', package_name, str(e))
    
    async def scan_exploit_db(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan Exploit Database with AI-powered analysis"""
        try:
            url = f"{self.DATABASES['exploit_db']['base_url']}?text={quote(package_name)}"
            
            # Check if AI analysis is available
            ai_result = None
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    self.logger.debug(f"Running AI Exploit Database analysis for {package_name} v{current_version}")
                    # Use a specialized prompt for Exploit Database analysis
                    ai_result = await self.ai_analyzer.analyze_exploit_db_result(
                        package_name=package_name,
                        current_version=current_version,
                        exploit_db_lookup_url=url
                    )
                    self.logger.debug(f"AI Exploit Database analysis completed: {ai_result}")
                except Exception as e:
                    self.logger.error(f"AI Exploit Database analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed: {str(e)}"
            
            # Generate result based on AI analysis or fallback to manual review
            if ai_result and "AI analysis not available" not in ai_result and "AI analysis failed" not in ai_result:
                summary = self._standardize_no_risk_message('exploit_db', ai_result)
                note = f"AI-powered Exploit Database analysis completed. Original URL for manual verification: {url}"
                self.logger.info(f"‚úÖ AI Exploit Database analysis completed for {package_name} v{current_version}: {ai_result[:100]}...")
            else:
                summary = f"Manual review required - check {url}"
                note = 'Exploit Database requires manual review of search results'
                if not self.ai_analyzer or not self.ai_analyzer.is_enabled():
                    note += " (AI analysis not available)"
                elif ai_result:
                    self.logger.warning(f"AI Exploit Database analysis failed for {package_name}: {ai_result[:100]}...")
                else:
                    self.logger.warning(f"No AI Exploit Database result for {package_name} v{current_version}")
            
            return {
                'database': 'Exploit Database',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': False,  # Will be updated by AI analysis parsing
                'vulnerability_count': 0,  # Will be updated by AI analysis parsing
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning Exploit Database for {package_name}: {e}")
            return self._error_result('exploit_db', package_name, str(e))
    
    async def scan_github_advisory(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Scan GitHub Security Advisory with AI-powered analysis"""
        try:
            if github_url and 'github.com' in github_url:
                # If we have a GitHub URL, use the specific repository advisory URL
                repo_match = re.search(r'github\.com/([^/]+)/([^/]+)', github_url)
                if repo_match:
                    owner, repo = repo_match.groups()
                    url = f"https://github.com/{owner}/{repo}/security/advisories"
                else:
                    url = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
            else:
                url = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
            
            # Use AI analysis if available and current_version is provided
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    ai_result = await self.ai_analyzer.analyze_github_advisory_result(
                        package_name, current_version, url
                    )
                    summary = self._standardize_no_risk_message('github_advisory', ai_result)
                    note = f'AI-powered GitHub Security Advisory analysis for {package_name} v{current_version}'
                except Exception as e:
                    self.logger.warning(f"AI GitHub Security Advisory analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed - manual review required: {str(e)}"
                    summary = f"Manual review required - check {url}"
                    note = 'AI analysis failed - manual review required'
            else:
                ai_result = "Manual review required"
                summary = f"Manual review required - check {url}"
                note = 'GitHub Security Advisory requires manual review of search results'
            
            return {
                'database': 'GitHub Security Advisory',
                'package_name': package_name,
                'search_url': url,
                'found_vulnerabilities': False,
                'vulnerability_count': 0,
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning GitHub Advisory for {package_name}: {e}")
            return self._error_result('github_advisory', package_name, str(e))
    
    async def scan_all_databases(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Scan all databases for a package"""
        self.logger.info(f"Scanning all databases for package: {package_name}")
        
        # Create tasks for all database scans (include current_version for AI analysis)
        tasks = [
            self.scan_nist_nvd(package_name, current_version),
            self.scan_mitre_cve(package_name, current_version),
            self.scan_snyk(package_name, current_version),
            self.scan_exploit_db(package_name, current_version),
            self.scan_github_advisory(package_name, github_url, current_version)
        ]
        
        # Run all scans concurrently
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        scan_results = {}
        total_vulnerabilities = 0
        databases_with_vulnerabilities = []
        
        database_names = ['nist_nvd', 'mitre_cve', 'snyk', 'exploit_db', 'github_advisory']
        
        for i, result in enumerate(results):
            db_name = database_names[i]
            
            if isinstance(result, Exception):
                self.logger.error(f"Error scanning {db_name}: {result}")
                scan_results[db_name] = self._error_result(db_name, package_name, str(result))
            else:
                scan_results[db_name] = result
                if result.get('found_vulnerabilities', False):
                    total_vulnerabilities += result.get('vulnerability_count', 0)
                    databases_with_vulnerabilities.append(result.get('database', db_name))
        
        # Generate summary
        if total_vulnerabilities > 0:
            summary = f"Found {total_vulnerabilities} vulnerabilities across {len(databases_with_vulnerabilities)} databases"
        else:
            summary = "No vulnerabilities found in any database"
        
        return {
            'package_name': package_name,
            'scan_results': scan_results,
            'total_vulnerabilities': total_vulnerabilities,
            'databases_with_vulnerabilities': databases_with_vulnerabilities,
            'summary': summary,
            'scanned_at': datetime.now().isoformat(),
            'scan_urls': self._build_search_urls(package_name)
        }
    
    def _empty_result(self, database: str, package_name: str, url: str) -> Dict[str, Any]:
        """Generate empty result structure with standardized messages"""
        # Use standardized messages based on database type
        if database == 'github_advisory':
            summary = "No published security advisories"
        else:
            summary = "None found"
            
        return {
            'database': self.DATABASES[database]['name'],
            'package_name': package_name,
            'search_url': url,
            'found_vulnerabilities': False,
            'vulnerability_count': 0,
            'vulnerabilities': [],
            'summary': summary,
            'scanned_at': datetime.now().isoformat()
        }
    
    def _error_result(self, database: str, package_name: str, error_msg: str) -> Dict[str, Any]:
        """Generate error result structure"""
        return {
            'database': self.DATABASES[database]['name'],
            'package_name': package_name,
            'search_url': '',
            'found_vulnerabilities': False,
            'vulnerability_count': 0,
            'vulnerabilities': [],
            'summary': f"Error scanning {self.DATABASES[database]['name']}: {error_msg}",
            'scanned_at': datetime.now().isoformat(),
            'error': error_msg
        }
    
    def _standardize_no_risk_message(self, database: str, ai_result: str = None) -> str:
        """Standardize 'no risk found' messages based on database and AI result"""
        if ai_result and "NOT_FOUND" in ai_result.upper():
            # AI analysis found no vulnerabilities - use standardized message
            if database == 'github_advisory':
                return "No published security advisories"
            else:
                return "None found"
        elif ai_result and "FOUND" in ai_result.upper():
            # AI analysis found vulnerabilities - keep the AI result
            return ai_result
        else:
            # Fallback for manual review or error cases
            return ai_result or "Manual review required"
    
    def generate_recommendations(self, package_name: str, current_version: str, 
                               latest_version: str, vulnerability_results: Dict[str, Any]) -> str:
        """Generate enhanced recommendations with proper SAFE vs VULNERABLE classification (Phase 1)"""
        
        # Analyze results from all vulnerability databases (M, P, R, T, V)
        scan_results = vulnerability_results.get('scan_results', {})
        
        # Phase 1: Enhanced classification of each database result
        classifications = {
            'vulnerable': [],      # Confirmed security risks requiring action
            'safe': [],           # CVEs found but current version not affected  
            'manual_review': [],  # Requires human assessment
            'none_found': []      # No relevant vulnerabilities
        }
        
        # Database display names
        db_names = {
            'github_advisory': 'GitHub Advisory',
            'nist_nvd': 'NIST NVD', 
            'mitre_cve': 'MITRE CVE',
            'snyk': 'SNYK',
            'exploit_db': 'Exploit Database'
        }
        
        # Classify each database result
        for db_name, result in scan_results.items():
            if db_name in db_names:
                classification = self._classify_database_result_enhanced(result, db_name)
                
                classifications[classification['status']].append({
                    'database': db_names[db_name],
                    'db_key': db_name,
                    'count': classification['count'],
                    'severity': classification.get('severity', 'UNKNOWN'),
                    'note': classification.get('note', '')
                })
        
        # Phase 1: Multi-tier recommendation logic
        recommendations = []
        action_prefix = ""
        
        # Tier 1: Security Issues (Highest Priority)
        if classifications['vulnerable']:
            total_vulns = sum(item['count'] for item in classifications['vulnerable'])
            highest_severity = self._get_highest_severity_enhanced([item['severity'] for item in classifications['vulnerable']])
            
            action_prefix = "üö® SECURITY RISK"
            recommendations.append(f"{total_vulns} confirmed vulnerabilities found")
            
            if highest_severity in ['CRITICAL', 'HIGH']:
                recommendations.append(f"‚ö° HIGH PRIORITY: {highest_severity} severity detected")
            
            # Show vulnerable sources
            vuln_sources = []
            for item in classifications['vulnerable']:
                count_text = f"{item['count']} ({item['severity']})" if item['severity'] != 'UNKNOWN' else str(item['count'])
                vuln_sources.append(f"{item['database']}: {count_text}")
            recommendations.append(f"Sources: {', '.join(vuln_sources)}")
            recommendations.append("‚ö†Ô∏è Review security advisories before deployment")
            
            # Version update for vulnerable packages
            if current_version != latest_version:
                recommendations.insert(1, f"üì¶ UPDATE REQUIRED: {current_version} ‚Üí {latest_version}")
        
        # Tier 2: Manual Review Required (when no confirmed vulnerabilities)
        elif classifications['manual_review']:
            manual_sources = [item['database'] for item in classifications['manual_review']]
            action_prefix = "üîç MANUAL REVIEW"
            recommendations.append(f"{', '.join(manual_sources)} require human assessment")
            
            # Show details for manual review
            for item in classifications['manual_review']:
                if item['note']:
                    recommendations.append(f"‚Ä¢ {item['database']}: {item['note']}")
            
            recommendations.append("üìã Human review needed for indeterminate cases")
        
        # Tier 3: Version Updates (when no security risks or manual review)
        else:
            version_update_needed = current_version != latest_version
            if version_update_needed:
                action_prefix = "‚úÖ PROCEED WITH UPDATE"
                recommendations.append(f"üì¶ UPDATE AVAILABLE: {current_version} ‚Üí {latest_version}")
                recommendations.append("‚úÖ No security risks detected - safe to update")
            else:
                action_prefix = "‚úÖ PROCEED"
        
        # Tier 4: Additional Information (SAFE findings)
        if classifications['safe']:
            safe_count = sum(item['count'] for item in classifications['safe'])
            safe_sources = [item['database'] for item in classifications['safe']]
            info_text = f"‚ÑπÔ∏è INFO: {safe_count} CVEs found but current version not affected"
            if len(safe_sources) <= 2:
                info_text += f" ({', '.join(safe_sources)})"
            recommendations.append(info_text)
        
        # Return final recommendation
        if recommendations:
            return f"{action_prefix} | {' | '.join(recommendations)}"
        else:
            return action_prefix or "‚úÖ PROCEED"
    
    def _is_python_cve_relevant_enhanced_nist(self, package_name: str, cve_id: str, 
                                             description: str, cve_data: Dict) -> bool:
        """Enhanced relevance check for Python packages in NIST NVD with improved false positive detection"""
        package_lower = package_name.lower()
        desc_lower = description.lower()
        
        # First, check for explicit Python package indicators (high confidence)
        python_indicators = [
            f"python {package_lower}",
            f"pip install {package_lower}",
            f"pypi {package_lower}",
            f"{package_lower} python package",
            f"{package_lower} python library",
            f"python's {package_lower}",
            f"python-{package_lower}",
            f"the {package_lower} package for python",
            f"the {package_lower} library for python"
        ]
        
        if any(indicator in desc_lower for indicator in python_indicators):
            return True
        
        # Check for hard exclusion patterns - these definitely indicate it's NOT the Python package
        hard_exclusions = [
            f"wordpress plugin",              # WordPress plugins
            f"wordpress theme",               # WordPress themes  
            f"drupal module",                 # Drupal modules
            f"joomla extension",              # Joomla extensions
            f"php plugin",                    # PHP plugins
            f"lib{package_lower}",            # C libraries
            f"{package_lower}.c",             # C source files
            f"{package_lower}.h",             # C header files
            f"{package_lower}.exe",           # Windows executables
            f"{package_lower}.dll",           # Windows libraries
            f"rust crate",                    # Rust crates
            f"ruby gem",                     # Ruby gems
            f"perl module",                  # Perl modules
            f"golang",                       # Go packages
            f"node.js",                      # Node.js specific
            f"npm package",                  # npm packages
            f".NET framework",               # .NET libraries
            f"java library",                 # Java libraries
            f"android app",                  # Android applications
            f"ios app"                       # iOS applications
        ]
        
        # If any hard exclusion is found, definitely not the Python package
        if any(pattern in desc_lower for pattern in hard_exclusions):
            return False
        
        # Soft exclusions - check with more context
        soft_exclusions = ["wordpress", "drupal", "joomla", "java", "php", "ruby", "perl", "golang", "node", "npm", ".net"]
        exclusion_found = any(excl in desc_lower for excl in soft_exclusions)
        
        # Package-specific false positive detection
        if package_lower == 'tabulate':
            # Check for WordPress/web-related false positives
            web_related_patterns = [
                'wordpress', 'drupal', 'joomla', 'plugin', 'theme', 'extension',
                'web application', 'website', 'cms', 'content management'
            ]
            if any(pattern in desc_lower for pattern in web_related_patterns):
                # Only include if there's strong Python context
                strong_python_context = [
                    'python tabulate', 'pypi tabulate', 'pip install tabulate',
                    'import tabulate', 'from tabulate', 'python table',
                    'python formatting', 'python library'
                ]
                return any(pattern in desc_lower for pattern in strong_python_context)
        
        # Known Python packages whitelist - be more permissive for these
        known_python_packages = [
            'lxml', 'requests', 'urllib3', 'flask', 'django', 'jinja2',
            'pandas', 'numpy', 'scipy', 'matplotlib', 'pillow', 'cryptography',
            'click', 'pyyaml', 'beautifulsoup4', 'sqlalchemy', 'psycopg2',
            'redis', 'celery', 'gunicorn', 'uwsgi', 'tornado', 'aiohttp',
            'fastapi', 'starlette', 'pydantic', 'marshmallow', 'pytest',
            'tox', 'coverage', 'mypy', 'black', 'flake8', 'isort', 'bandit',
            'setuptools', 'wheel', 'pip', 'virtualenv', 'conda', 'tabulate',
            'openpyxl', 'xlsxwriter', 'xlrd', 'xlwt', 'pywin32', 'transformers',
            'paramiko', 'pyjwt', 'jwt', 'cffi', 'mistune', 'markdown',
            'tables', 'pytables', 'h5py', 'bokeh', 'plotly', 'seaborn',
            'scikit-learn', 'sklearn', 'tensorflow', 'keras', 'torch', 'pytorch',
            'scrapy', 'twisted', 'channels', 'celery', 'kombu', 'billiard'
        ]
        
        if package_lower in known_python_packages and package_lower in desc_lower:
            # For known Python packages, only exclude if soft exclusions with strong context
            if exclusion_found:
                # Check if the exclusion has strong context (not just a passing mention)
                exclusion_context_patterns = [
                    f"wordpress {package_lower}",
                    f"drupal {package_lower}",  
                    f"java {package_lower}",
                    f"php {package_lower}",
                    f"{package_lower} for wordpress",
                    f"{package_lower} plugin",
                    f"{package_lower} theme"
                ]
                if any(pattern in desc_lower for pattern in exclusion_context_patterns):
                    return False
            # For known Python packages, assume relevant unless hard exclusions
            return True
        
        # For very common words that often appear in non-Python contexts
        very_common_words = ['regex', 'json', 'xml', 'html', 'http', 'url', 'file', 'time', 'date', 'math', 'test', 'mock']
        if package_lower in very_common_words:
            # Require explicit Python context for common words
            return self._has_explicit_python_context(package_lower, desc_lower)
        
        # For package name mentions, apply broader Python context indicators
        if package_lower in desc_lower:
            # Broader Python context indicators
            python_context_indicators = [
                "python", "pip", "pypi", "django", "flask", "numpy", "pandas", 
                "setuptools", "wheel", "conda", "virtualenv", "wsgi", "asgi",
                "pytest", "unittest", "import", "module", "package", "library",
                "__init__.py", "requirements.txt", "setup.py", "pyproject.toml",
                # Additional context indicators for Python packages
                "cve", "vulnerability", "security", "exploit", "disclosure",
                "version", "versions", "affected", "before", "through", "prior",
                # Web/HTTP related terms common in Python web frameworks
                "http", "web", "server", "client", "api", "request", "response"
            ]
            
            # If soft exclusions found, require stronger Python context
            if exclusion_found:
                strong_python_indicators = [
                    "python", "pip", "pypi", "django", "flask", "pytest", 
                    "setuptools", "wheel", "__init__.py", "setup.py",
                    # Also accept if it's clearly a security vulnerability
                    "cve", "vulnerability", "security", "exploit"
                ]
                return any(indicator in desc_lower for indicator in strong_python_indicators)
            else:
                # No exclusions - if package name is mentioned and there are any contextual indicators, include it
                # This makes the filter more permissive while still filtering out completely unrelated results
                return any(indicator in desc_lower for indicator in python_context_indicators)
        
        # Check CPE configurations for Python package matches
        configurations = cve_data.get('configurations', {})
        nodes = configurations.get('nodes', [])
        for node in nodes:
            cpe_matches = node.get('cpeMatch', [])
            for cpe in cpe_matches:
                cpe_criteria = cpe.get('criteria', '').lower()
                # Look for Python-specific CPE patterns
                if (package_lower in cpe_criteria and 
                    ('python' in cpe_criteria or 'pip' in cpe_criteria)):
                    return True
        
        return False

    def _is_python_cve_relevant(self, package_name: str, cve_id: str, 
                               description: str, cve_data: Dict) -> bool:
        """Enhanced relevance check for Python packages in NIST NVD"""
        # Use the enhanced version
        return self._is_python_cve_relevant_enhanced_nist(package_name, cve_id, description, cve_data)
    
    def _get_enhanced_search_urls(self, base_url: str, package_name: str) -> List[str]:
        """Get enhanced search URLs with comprehensive strategies for better coverage"""
        package_lower = package_name.lower()
        
        # Known Python packages that often have many CVEs
        known_python_packages = [
            'lxml', 'pillow', 'pil', 'django', 'flask', 'requests', 'urllib3', 'paramiko', 
            'pycryptodome', 'cryptography', 'sqlalchemy', 'jinja2', 'tornado', 'twisted',
            'pyramid', 'cherrypy', 'bottle', 'fastapi', 'aiohttp', 'httpx', 'pyyaml',
            'markdown', 'bleach', 'beautifulsoup4', 'lxml', 'defusedxml', 'xml', 'html5lib',
            'tables', 'numpy', 'pandas', 'scipy', 'matplotlib', 'scikit-learn', 'nltk',
            'transformers', 'tensorflow', 'pytorch', 'opencv-python', 'cv2', 'tabulate'
        ]
        
        # Common words that appear frequently in CVE descriptions but aren't necessarily the Python package
        common_words = ['regex', 'json', 'xml', 'html', 'http', 'url', 'file', 'time', 'date', 'math', 'test', 'mock', 'tables', 'markdown']
        
        # Build comprehensive search strategies
        search_urls = []
        
        if package_lower in known_python_packages:
            # For known Python packages, use comprehensive search strategy
            search_urls = [
                f"{base_url}?keywordSearch={quote(package_name)}",  # Broad search first
                f"{base_url}?keywordSearch=python%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pip%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pypi%20{quote(package_name)}",
                f"{base_url}?keywordSearch=python-{quote(package_name)}",
                f"{base_url}?keywordSearch={quote(package_name)}%20python",
                f"{base_url}?keywordSearch={quote(package_name)}%20package",
                f"{base_url}?keywordSearch={quote(package_name)}%20library"
            ]
        elif package_lower in common_words:
            # For common words, prioritize Python-specific searches but include broad search
            search_urls = [
                f"{base_url}?keywordSearch={quote(package_name)}",  # Include broad search
                f"{base_url}?keywordSearch=python%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pip%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pypi%20{quote(package_name)}",
                f"{base_url}?keywordSearch=python-{quote(package_name)}",
                f"{base_url}?keywordSearch={quote(package_name)}%20python"
            ]
        else:
            # For other package names, use broader search strategy with more variations
            search_urls = [
                f"{base_url}?keywordSearch={quote(package_name)}",
                f"{base_url}?keywordSearch=python%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pip%20{quote(package_name)}",
                f"{base_url}?keywordSearch=pypi%20{quote(package_name)}",
                f"{base_url}?keywordSearch=python-{quote(package_name)}"
            ]
        
        return search_urls
    
    def _has_explicit_python_context(self, package_name: str, description: str) -> bool:
        """Check if description has explicit Python context for common package names"""
        # Strong Python indicators
        strong_python_indicators = [
            'python package',
            'python library', 
            'python module',
            'pip install',
            'pypi',
            'setuptools',
            'wheel',
            'conda',
            '__init__.py',
            'import ' + package_name,
            'from ' + package_name,
            'python ' + package_name + ' package',
            'python ' + package_name + ' library',
            'python-' + package_name,
            package_name + ' python',
            package_name + ' package for python',
            package_name + ' library for python',
            'the ' + package_name + ' package for python',
            'the ' + package_name + ' library for python',
            package_name + ' for python',
            'the ' + package_name + ' for python'
        ]
        
        return any(indicator in description for indicator in strong_python_indicators)
    
    def _is_mitre_cve_relevant_enhanced(self, package_name: str, cve_info: Dict) -> bool:
        """Enhanced relevance check for MITRE CVE data with improved filtering"""
        description = cve_info.get('description', '').lower()
        package_lower = package_name.lower()
        
        
        # First, check for explicit Python package indicators (high confidence)
        python_indicators = [
            f"python {package_lower}",
            f"pip install {package_lower}",
            f"pypi {package_lower}",
            f"{package_lower} python package",
            f"{package_lower} python library",
            f"python's {package_lower}",
            f"python-{package_lower}",
            f"the {package_lower} package for python",
            f"the {package_lower} library for python"
        ]
        
        if any(indicator in description for indicator in python_indicators):
            return True
        
        # Check for hard exclusion patterns - these definitely indicate it's NOT the Python package
        hard_exclusions = [
            f"lib{package_lower}",      # C libraries
            f"{package_lower}.c",       # C source files
            f"{package_lower}.h",       # C header files
            f"{package_lower}.exe",     # Windows executables
            f"{package_lower}.dll",     # Windows libraries
            f"rust crate",              # Rust crates
            f"ruby gem",               # Ruby gems
            f"perl module",            # Perl modules
            f"golang",                 # Go packages
            f"node.js",                # Node.js specific
            f"npm package",            # npm packages
            f".NET framework",         # .NET libraries
            f"java library",           # Java libraries
            f"android app",            # Android specific (more specific to avoid false positives)
            f"android application",    # Android specific 
            f"ios app",                # iOS specific (more specific to avoid JWT 'iss' false positive)
            f"ios application"         # iOS specific
        ]
        
        # Check if this is a known Python package explicitly mentioned in description
        known_python_packages = [
            'werkzeug', 'flask', 'django', 'requests', 'urllib3', 'jinja2', 
            'pandas', 'numpy', 'scipy', 'matplotlib', 'pillow', 'cryptography',
            'click', 'pyyaml', 'lxml', 'beautifulsoup4', 'sqlalchemy', 'psycopg2',
            'redis', 'celery', 'gunicorn', 'uwsgi', 'tornado', 'aiohttp',
            'fastapi', 'starlette', 'pydantic', 'marshmallow', 'pytest',
            'tox', 'coverage', 'mypy', 'black', 'flake8', 'isort', 'bandit',
            'zipp', 'setuptools', 'wheel', 'pip', 'virtualenv', 'conda',
            'mistune', 'paramiko', 'pyjwt', 'jwt', 'ssh', 'markdown'
        ]
        
        is_known_python_package = package_lower in known_python_packages
        package_explicitly_mentioned = package_lower in description
        
        # For known Python packages that are explicitly mentioned, be more permissive with hard exclusions
        # This handles cross-platform CVEs that affect multiple language implementations
        if is_known_python_package and package_explicitly_mentioned:
            # Check for language-specific exclusions that would indicate it's NOT about the Python package
            language_specific_exclusions = [
                f"java {package_lower}",
                f"php {package_lower}", 
                f"ruby {package_lower}",
                f"golang {package_lower}",
                f"node.js {package_lower}",
                f"{package_lower} for java",
                f"{package_lower} for php",
                f"{package_lower} for ruby",
                f"{package_lower} for golang",
                f"{package_lower} for node.js",
                f"lib{package_lower}",      # C libraries  
                f"{package_lower}.c",       # C source files
                f"{package_lower}.h",       # C header files
                f"{package_lower}.exe",     # Windows executables
                f"{package_lower}.dll"      # Windows libraries
            ]
            
            # Only exclude if there's specific language context for this package
            if any(pattern in description for pattern in language_specific_exclusions):
                return False
            # Otherwise, continue with the rest of the logic (don't exclude based on general language mentions)
        else:
            # For non-known packages or packages not explicitly mentioned, apply hard exclusions as before
            if any(pattern in description for pattern in hard_exclusions):
                return False
        
        # Soft exclusions - check with more context
        soft_exclusions = ["java", "php", "ruby", "perl", "golang", "node", "npm", ".net"]
        exclusion_found = any(excl in description for excl in soft_exclusions)
        
        # For package name mentions, apply different logic based on package type
        if package_lower in description:
            # For very common words that often appear in non-Python contexts, require explicit Python context
            very_common_words = ['regex', 'json', 'xml', 'html', 'http', 'url', 'file', 'time', 'date', 'math', 'test', 'mock']
            
            # Special handling for packages that are common words but have specific patterns
            zip_related_false_positives = [
                'zip file', 'zip archive', 'zip compression', 'zip utility', 'zip library',
                'compressed zip', 'extract zip', 'zip extraction', 'zip format', 'zip bomb',
                'malicious zip', 'zip attack', 'unzip', 'winzip', '7zip', 'zip64',
                'zipinfo', 'zipimport', 'gzip', 'bzip', 'deflate'
            ]
            
            if package_lower == 'zipp':
                # For zipp, check for ZIP file related false positives first
                if any(pattern in description for pattern in zip_related_false_positives):
                    # This is likely about ZIP files, not the Python zipp package
                    # Only include if there's strong Python context
                    strong_python_context = [
                        'python zipp', 'pypi zipp', 'pip install zipp',
                        'zipp python package', 'import zipp', 'from zipp',
                        'importlib.metadata', 'backport', 'python 3.',
                        'setuptools', 'pkg_resources'
                    ]
                    return any(pattern in description for pattern in strong_python_context)
                else:
                    # No ZIP file indicators, check for Python context more broadly
                    return self._has_explicit_python_context(package_lower, description)
            
            elif package_lower in very_common_words:
                return self._has_explicit_python_context(package_lower, description)
            
            # For known Python packages, be more permissive (unless hard exclusions apply)
            if is_known_python_package:
                # For known Python packages, only exclude if soft exclusions with strong context
                if exclusion_found:
                    # Check if the exclusion has strong context (not just a passing mention)
                    exclusion_context_patterns = [
                        f"java {package_lower}",
                        f"php {package_lower}",
                        f"ruby {package_lower}",
                        f"{package_lower} for java",
                        f"{package_lower} for php",
                        f"{package_lower} for ruby"
                    ]
                    if any(pattern in description for pattern in exclusion_context_patterns):
                        return False
                # For known Python packages, assume relevant unless hard exclusions
                return True
            
            # For other packages, use broader Python context indicators
            python_context_indicators = [
                "python", "pip", "pypi", "django", "flask", "numpy", "pandas", 
                "setuptools", "wheel", "conda", "virtualenv", "wsgi", "asgi",
                "pytest", "unittest", "import", "module", "package", "library",
                "__init__.py", "requirements.txt", "setup.py", "pyproject.toml",
                ".py", "python implementation", "python library", "python package"
            ]
            
            # If soft exclusions found, require stronger Python context
            if exclusion_found:
                strong_python_indicators = [
                    "python", "pip", "pypi", "django", "flask", "pytest", 
                    "setuptools", "wheel", "__init__.py", "setup.py", ".py"
                ]
                return any(indicator in description for indicator in strong_python_indicators)
            else:
                # No exclusions, check for any Python context
                return any(indicator in description for indicator in python_context_indicators)
        
        return False

    def _is_mitre_cve_relevant(self, package_name: str, cve_info: Dict) -> bool:
        """Enhanced relevance check for MITRE CVE data - Python specific"""
        # Use the enhanced version
        return self._is_mitre_cve_relevant_enhanced(package_name, cve_info)
    
    def _check_version_affected_nist(self, cve_data: Dict, current_version: str, 
                                   package_name: str) -> bool:
        """Check if current version is affected based on NIST NVD data"""
        if not current_version or current_version == "NEW":
            return False
            
        try:
            # Parse version for comparison
            from packaging import version
            current_ver = version.parse(current_version)
            
            # Check configurations for version ranges
            configurations = cve_data.get('configurations', {})
            nodes = configurations.get('nodes', [])
            
            for node in nodes:
                cpe_matches = node.get('cpeMatch', [])
                for cpe in cpe_matches:
                    cpe_name = cpe.get('criteria', '').lower()
                    if package_name.lower() in cpe_name:
                        # Check version constraints
                        if cpe.get('vulnerable', True):
                            version_start = cpe.get('versionStartIncluding')
                            version_end = cpe.get('versionEndExcluding')
                            version_start_ex = cpe.get('versionStartExcluding')
                            version_end_in = cpe.get('versionEndIncluding')
                            
                            # Check if version falls in vulnerable range
                            if self._version_in_range(current_ver, version_start, version_end, 
                                                    version_start_ex, version_end_in):
                                return True
                                
        except Exception as e:
            self.logger.debug(f"Error checking version for {package_name}: {e}")
            
        return False
    
    def _check_version_affected_mitre(self, cve_data: Dict, current_version: str, 
                                    package_name: str) -> bool:
        """Check if current version is affected based on MITRE CVE data (same as NIST)"""
        return self._check_version_affected_nist(cve_data, current_version, package_name)
    
    def _version_in_range(self, current_ver, version_start=None, version_end=None,
                         version_start_ex=None, version_end_in=None) -> bool:
        """Check if version falls within vulnerability range"""
        try:
            from packaging import version
            
            # Check start constraints
            if version_start:
                if current_ver < version.parse(version_start):
                    return False
                    
            if version_start_ex:
                if current_ver <= version.parse(version_start_ex):
                    return False
            
            # Check end constraints  
            if version_end:
                if current_ver >= version.parse(version_end):
                    return False
                    
            if version_end_in:
                if current_ver > version.parse(version_end_in):
                    return False
                    
            return True
            
        except Exception:
            # If version parsing fails, assume potentially vulnerable
            return True
    
    def _check_version_in_snyk_range(self, current_version: str, 
                                   affected_versions: List[str]) -> bool:
        """Check if current version is in SNYK affected version ranges"""
        if not current_version or not affected_versions:
            return False
            
        try:
            from packaging import version
            current_ver = version.parse(current_version)
            
            for version_range in affected_versions:
                # Parse SNYK version range formats like "<2.28.0", ">=1.0.0,<2.0.0"
                if self._parse_snyk_version_range(current_ver, version_range):
                    return True
                    
        except Exception as e:
            self.logger.debug(f"Error parsing SNYK version range: {e}")
            
        return False
    
    def _classify_database_result_enhanced(self, result: Dict[str, Any], db_name: str) -> Dict[str, Any]:
        """Enhanced classification with proper SAFE vs VULNERABLE distinction (Phase 1)"""
        summary = result.get('summary', '').lower()
        ai_analysis = result.get('ai_analysis', '').lower() if result.get('ai_analysis') else ''
        vulnerability_count = result.get('vulnerability_count', 0)
        
        # Phase 1 Fix 1: Priority classification to distinguish SAFE from VULNERABLE
        
        # Priority 1: Check for explicit SAFE indication (CVEs found but version not affected)
        if ('safe -' in summary and 'not affected' in summary) or \
           ('safe -' in summary and 'but v' in summary):
            return {
                'status': 'safe',
                'count': vulnerability_count,  # Keep count for information
                'severity': self._extract_severity_robust(result),
                'note': f'{vulnerability_count} CVEs found but current version not affected'
            }
        
        # Priority 2: Check for explicit VULNERABLE indication
        if ('vulnerable -' in summary and 'affect' in summary) or \
           ('vulnerable -' in summary and 'cves affect' in summary):
            return {
                'status': 'vulnerable',
                'count': vulnerability_count,
                'severity': self._extract_severity_robust(result),
                'note': f'{vulnerability_count} CVEs affect current version'
            }
        
        # Phase 1 Fix 3: Apply < 10 CVE threshold logic (align with individual columns)
        if 'manual review required' in summary:
            if vulnerability_count < 10:
                # Convert to SAFE per threshold logic
                return {
                    'status': 'safe',
                    'count': 0,  # Treat as safe, no security risk
                    'severity': 'NONE',
                    'note': f'{vulnerability_count} CVEs found but < 10 threshold - treated as SAFE'
                }
            else:
                # Keep as manual review for ‚â• 10 CVEs
                return {
                    'status': 'manual_review',
                    'count': 0,  # Manual review, not confirmed risk
                    'severity': 'UNKNOWN',
                    'note': f'{vulnerability_count} CVEs require manual assessment'
                }
        
        # Priority 4: Check for explicit "none found" or "no published"
        if 'none found' in summary or 'no published' in summary:
            return {
                'status': 'none_found',
                'count': 0,
                'severity': 'NONE',
                'note': 'No relevant vulnerabilities found'
            }
        
        # Priority 5: Check AI analysis for Exploit Database
        if db_name == 'exploit_db' and ai_analysis:
            if 'not_found' in ai_analysis or 'no exploits found' in ai_analysis:
                return {
                    'status': 'none_found',
                    'count': 0,
                    'severity': 'NONE',
                    'note': 'No exploits found'
                }
            elif ': found' in ai_analysis and 'not_found' not in ai_analysis:
                return {
                    'status': 'vulnerable',
                    'count': max(vulnerability_count, 1),
                    'severity': self._extract_severity_robust(result),
                    'note': 'Exploits found via AI analysis'
                }
        
        # Priority 6: Legacy logic for edge cases
        # Check explicit found_vulnerabilities flag
        if result.get('found_vulnerabilities', False) and vulnerability_count > 0:
            # Need to determine if this is SAFE or VULNERABLE based on summary context
            if 'but v' in summary and 'not affected' in summary:
                return {
                    'status': 'safe',
                    'count': vulnerability_count,
                    'severity': self._extract_severity_robust(result),
                    'note': f'{vulnerability_count} CVEs found but version not affected'
                }
            else:
                return {
                    'status': 'vulnerable',
                    'count': vulnerability_count,
                    'severity': self._extract_severity_robust(result),
                    'note': f'{vulnerability_count} vulnerabilities detected'
                }
        
        # Default: No vulnerabilities found
        return {
            'status': 'none_found',
            'count': 0,
            'severity': 'NONE',
            'note': 'No vulnerabilities detected'
        }
    
    def _extract_severity_robust(self, result: Dict[str, Any]) -> str:
        """Extract severity with multiple fallback methods"""
        
        # Method 1: AI analysis patterns
        ai_analysis = result.get('ai_analysis', '').lower()
        for severity in ['critical', 'high', 'medium', 'low']:
            if f'severity: {severity}' in ai_analysis or f'severity {severity}' in ai_analysis:
                return severity.upper()
        
        # Method 2: Summary text patterns  
        summary = result.get('summary', '').lower()
        if 'critical' in summary:
            return 'CRITICAL'
        elif 'high' in summary:
            return 'HIGH'
        elif 'medium' in summary:
            return 'MEDIUM'
        elif 'low' in summary:
            return 'LOW'
        
        # Method 3: Individual vulnerability severity
        vulnerabilities = result.get('vulnerabilities', [])
        if vulnerabilities:
            severities = [v.get('severity', 'UNKNOWN').upper() for v in vulnerabilities]
            return self._get_highest_severity_enhanced(severities)
        
        return 'UNKNOWN'
    
    def _get_highest_severity_enhanced(self, severities: List[str]) -> str:
        """Get the highest severity from a list of severities"""
        severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'UNKNOWN']
        
        for severity in severity_order:
            if severity in severities:
                return severity
                
        return 'UNKNOWN'
    
    def _parse_snyk_version_range(self, current_ver, version_range: str) -> bool:
        """Parse SNYK version range and check if current version is affected"""
        try:
            from packaging import version
            
            # Handle common SNYK version range formats
            if version_range.startswith('<'):
                max_ver = version.parse(version_range[1:])
                return current_ver < max_ver
            elif version_range.startswith('<='):
                max_ver = version.parse(version_range[2:])
                return current_ver <= max_ver
            elif version_range.startswith('>='):
                if ',' in version_range:
                    # Range like ">=1.0.0,<2.0.0"
                    parts = version_range.split(',')
                    min_ver = version.parse(parts[0][2:])  # Remove ">="
                    if parts[1].startswith('<'):
                        max_ver = version.parse(parts[1][1:])
                        return min_ver <= current_ver < max_ver
                else:
                    min_ver = version.parse(version_range[2:])
                    return current_ver >= min_ver
            elif version_range.startswith('>'):
                min_ver = version.parse(version_range[1:])
                return current_ver > min_ver
            elif ',' in version_range:
                # Complex range - evaluate each part
                parts = version_range.split(',')
                return all(self._parse_snyk_version_range(current_ver, part.strip()) 
                          for part in parts)
            else:
                # Exact version match
                return current_ver == version.parse(version_range)
                
        except Exception:
            return False
    
    async def _get_snyk_vulnerability_info(self, package_name: str, url: str) -> Optional[Dict]:
        """Get vulnerability information from SNYK (simplified version)"""
        try:
            # For now, we'll rely on AI analysis and NVD data
            # In a full implementation, this would scrape SNYK website
            # or use SNYK's paid API
            
            # Placeholder implementation - returns empty for now
            # In production, you might implement web scraping here
            return {'vulnerabilities': []}
            
        except Exception as e:
            self.logger.debug(f"Error getting SNYK vulnerability info: {e}")
            return None
    
    def _get_highest_severity(self, severities: List[str]) -> str:
        """Get the highest severity from a list of severities"""
        severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'UNKNOWN']
        
        for severity in severity_order:
            if severity in [s.upper() for s in severities if s]:
                return severity
                
        return 'UNKNOWN'
    
    def _extract_cvss_info(self, cve_data: Dict) -> tuple[str, str]:
        """Extract CVSS severity and score from CVE data"""
        severity = 'UNKNOWN'
        score = 'N/A'
        
        metrics = cve_data.get('metrics', {})
        
        # Try CVSS versions in order of preference
        for cvss_version in ['cvssMetricV31', 'cvssMetricV30', 'cvssMetricV3', 'cvssMetricV2']:
            if cvss_version in metrics and metrics[cvss_version]:
                cvss_metric = metrics[cvss_version][0]
                cvss_data = cvss_metric.get('cvssData', {})
                
                score = cvss_data.get('baseScore', 'N/A')
                severity = cvss_data.get('baseSeverity', 'UNKNOWN').upper()
                
                if severity != 'UNKNOWN' and score != 'N/A':
                    break
        
        return severity, str(score)
    
    def _severity_priority(self, severity: str) -> int:
        """Get priority value for severity sorting (higher number = higher priority)"""
        priority_map = {
            'CRITICAL': 4,
            'HIGH': 3, 
            'MEDIUM': 2,
            'LOW': 1,
            'UNKNOWN': 0
        }
        return priority_map.get(severity.upper(), 0)
    
    def _check_nist_version_impact(self, cve_data: Dict, current_version: str, 
                                  package_name: str) -> bool:
        """Enhanced version impact checking for NIST NVD data - returns None when no version constraints found"""
        if not current_version or current_version == "NEW":
            return False
            
        try:
            from packaging import version
            current_ver = version.parse(current_version)
            
            # Check all configuration nodes for version constraints
            configurations = cve_data.get('configurations', {})
            nodes = configurations.get('nodes', [])
            
            found_version_constraints = False
            
            for node in nodes:
                cpe_matches = node.get('cpeMatch', [])
                for cpe in cpe_matches:
                    cpe_criteria = cpe.get('criteria', '').lower()
                    
                    # Only check CPE entries that are vulnerable and related to our package
                    if (cpe.get('vulnerable', True) and 
                        package_name.lower() in cpe_criteria):
                        
                        # Extract version constraints
                        constraints = {
                            'version_start_including': cpe.get('versionStartIncluding'),
                            'version_start_excluding': cpe.get('versionStartExcluding'),
                            'version_end_including': cpe.get('versionEndIncluding'),
                            'version_end_excluding': cpe.get('versionEndExcluding')
                        }
                        
                        # Check if any version constraints exist
                        if any(constraints.values()):
                            found_version_constraints = True
                            if self._version_matches_constraints(current_ver, constraints):
                                return True
            
            # If we found version constraints but none matched, return False
            # If no version constraints found, return None to indicate manual review needed
            return False if found_version_constraints else None
                            
        except Exception as e:
            self.logger.debug(f"Version impact check failed for {package_name}: {e}")
            
        return None
    
    def _version_matches_constraints(self, current_ver, constraints: Dict) -> bool:
        """Check if version matches the given constraints"""
        try:
            from packaging import version
            
            # Check start constraints
            if constraints['version_start_including']:
                if current_ver < version.parse(constraints['version_start_including']):
                    return False
                    
            if constraints['version_start_excluding']:
                if current_ver <= version.parse(constraints['version_start_excluding']):
                    return False
            
            # Check end constraints
            if constraints['version_end_excluding']:
                if current_ver >= version.parse(constraints['version_end_excluding']):
                    return False
                    
            if constraints['version_end_including']:
                if current_ver > version.parse(constraints['version_end_including']):
                    return False
            
            return True
            
        except Exception:
            return False
    
    def _extract_affected_versions(self, cve_data: Dict, package_name: str) -> List[str]:
        """Extract affected version ranges from CVE data with robust error handling"""
        affected_versions = []
        
        try:
            configurations = cve_data.get('configurations', {})
            if not isinstance(configurations, dict):
                return affected_versions
            
            nodes = configurations.get('nodes', [])
            if not isinstance(nodes, list):
                return affected_versions
            
            for node in nodes:
                if not isinstance(node, dict):
                    continue
                    
                cpe_matches = node.get('cpeMatch', [])
                if not isinstance(cpe_matches, list):
                    continue
                    
                for cpe in cpe_matches:
                    if not isinstance(cpe, dict):
                        continue
                        
                    cpe_criteria = cpe.get('criteria', '')
                    if not isinstance(cpe_criteria, str):
                        continue
                        
                    cpe_criteria_lower = cpe_criteria.lower()
                    
                    if (cpe.get('vulnerable', True) and 
                        package_name.lower() in cpe_criteria_lower):
                        
                        version_range = []
                        
                        if cpe.get('versionStartIncluding'):
                            version_range.append(f">={cpe['versionStartIncluding']}")
                        if cpe.get('versionStartExcluding'):
                            version_range.append(f">{cpe['versionStartExcluding']}")
                        if cpe.get('versionEndExcluding'):
                            version_range.append(f"<{cpe['versionEndExcluding']}")
                        if cpe.get('versionEndIncluding'):
                            version_range.append(f"<={cpe['versionEndIncluding']}")
                        
                        if version_range:
                            affected_versions.append(','.join(version_range))
                            
        except Exception as e:
            self.logger.debug(f"Error extracting affected versions for {package_name}: {e}")
            
        return affected_versions
    
    async def _get_enhanced_mitre_cve_data(self, package_name: str) -> List[Dict]:
        """Enhanced MITRE CVE data retrieval with multiple search strategies"""
        try:
            all_results = []
            seen_cve_ids = set()
            
            # Strategy 1: Direct package name search
            search_terms = [package_name]
            
            # Strategy 2: Enhanced search terms for better coverage
            package_lower = package_name.lower()
            search_terms.extend([
                f"python {package_name}",
                f"python-{package_name}",
                f"pypi {package_name}",
                f"{package_name} python package"
            ])
            
            # For each search term, get results
            for term in search_terms[:3]:  # Limit to prevent too many API calls
                try:
                    nist_url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch={quote(term)}"
                    data = await self._rate_limited_request('nist_nvd', nist_url)
                    
                    if data and data.get('vulnerabilities'):
                        for vuln in data['vulnerabilities']:
                            cve_data = vuln.get('cve', {})
                            cve_id = cve_data.get('id', '')
                            
                            # Avoid duplicates
                            if cve_id and cve_id not in seen_cve_ids:
                                descriptions = cve_data.get('descriptions', [])
                                description = descriptions[0].get('value', '') if descriptions else ''
                                
                                severity, score = self._extract_cvss_info(cve_data)
                                
                                result = {
                                    'cve_id': cve_id,
                                    'description': description,
                                    'severity': severity,
                                    'score': score,
                                    'published': cve_data.get('published', ''),
                                    'modified': cve_data.get('lastModified', ''),
                                    'cve_data': cve_data  # Keep original data for version checking
                                }
                                
                                all_results.append(result)
                                seen_cve_ids.add(cve_id)
                
                except Exception as e:
                    self.logger.debug(f"Error with MITRE search term '{term}': {e}")
                    continue
            
            self.logger.debug(f"Enhanced MITRE search found {len(all_results)} unique CVEs for {package_name}")
            return all_results
            
        except Exception as e:
            self.logger.debug(f"Error in enhanced MITRE CVE data retrieval: {e}")
            return []

    async def _get_mitre_cve_data_via_nist(self, package_name: str) -> List[Dict]:
        """Get MITRE CVE data via NIST API (since they mirror the same data) - Legacy method"""
        try:
            nist_url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch={quote(package_name)}"
            data = await self._rate_limited_request('nist_nvd', nist_url)
            
            results = []
            if data and data.get('vulnerabilities'):
                for vuln in data['vulnerabilities']:
                    cve_data = vuln.get('cve', {})
                    descriptions = cve_data.get('descriptions', [])
                    description = descriptions[0].get('value', '') if descriptions else ''
                    
                    severity, score = self._extract_cvss_info(cve_data)
                    
                    results.append({
                        'cve_id': cve_data.get('id', ''),
                        'description': description,
                        'severity': severity,
                        'score': score,
                        'published': cve_data.get('published', ''),
                        'modified': cve_data.get('lastModified', ''),
                        'cve_data': cve_data  # Keep original data for version checking
                    })
            
            return results
            
        except Exception as e:
            self.logger.debug(f"Error getting MITRE CVE data via NIST: {e}")
            return []
    
    def _extract_version_from_description(self, description: str, current_version: str, 
                                         package_name: str) -> bool:
        """Fallback method to extract version constraints from CVE description"""
        if not description or not current_version:
            return False
            
        try:
            from packaging import version
            current_ver = version.parse(current_version)
            description_lower = description.lower()
            package_lower = package_name.lower()
            
            # Common patterns for version mentions in CVE descriptions
            version_patterns = [
                f"{package_lower} before ",
                f"{package_lower} versions before ",
                f"{package_lower} prior to ",
                f"{package_lower} < ",
                f"{package_lower} through ",
                f"{package_lower} up to ",
                "versions before ",
                "prior to version ",
                "before version ",
                "through version ",
                "up to version "
            ]
            
            import re
            
            # Look for version constraints in description
            for pattern in version_patterns:
                if pattern in description_lower:
                    # Extract version number after the pattern
                    pattern_pos = description_lower.find(pattern)
                    remaining_text = description[pattern_pos + len(pattern):].strip()
                    
                    # Extract version number using regex
                    version_match = re.search(r'(\d+(?:\.\d+)*(?:\.\d+)*)', remaining_text)
                    if version_match:
                        constraint_version = version_match.group(1)
                        try:
                            constraint_ver = version.parse(constraint_version)
                            # If current version is less than constraint, it's affected
                            if current_ver < constraint_ver:
                                self.logger.debug(f"Version constraint found in description: {package_name} {current_version} < {constraint_version}")
                                return True
                        except Exception:
                            continue
            
            # Look for exact version mentions
            version_mention_patterns = [
                f"{package_lower} {current_version}",
                f"version {current_version}",
                f"v{current_version}"
            ]
            
            for pattern in version_mention_patterns:
                if pattern in description_lower:
                    self.logger.debug(f"Current version mentioned in CVE description: {package_name} {current_version}")
                    return True
            
            return False
            
        except Exception as e:
            self.logger.debug(f"Failed to extract version from description for {package_name}: {e}")
            return False

    def _check_mitre_version_impact(self, cve_info: Dict, current_version: str, 
                                   package_name: str):
        """Check version impact for MITRE CVE with enhanced fallback logic - returns None when indeterminate"""
        if not current_version or current_version == "NEW":
            return False
        
        # First try standard CPE-based version checking
        if 'cve_data' in cve_info:
            has_version_info = self._check_nist_version_impact(
                cve_info['cve_data'], current_version, package_name
            )
            if has_version_info is not None:  # If we got definitive version info
                return has_version_info
        
        # Fallback: Try to extract version info from description
        description = cve_info.get('description', '')
        if description:
            description_result = self._extract_version_from_description(
                description, current_version, package_name
            )
            # If description parsing found something definitive, return it
            if description_result:
                return True
        
        # If neither CPE nor description provided definitive info, return None (indeterminate)
        return None
    
    async def _fetch_snyk_vulnerabilities(self, package_name: str, url: str) -> List[Dict]:
        """Fetch SNYK vulnerabilities with web scraping"""
        try:
            self.logger.debug(f"Fetching SNYK vulnerabilities for {package_name} from {url}")
            
            # Try multiple SNYK URL formats to ensure we find vulnerabilities
            search_urls = [
                f"https://security.snyk.io/package/pip/{package_name.lower()}",
                f"https://security.snyk.io/vuln/pip/{package_name.lower()}",
                f"https://snyk.io/vuln/pip:{package_name.lower()}"
            ]
            
            # Set headers to mimic browser request
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            }
            
            vulnerabilities = []
            
            # Try each SNYK URL format until we find vulnerabilities
            for search_url in search_urls:
                try:
                    self.logger.debug(f"Trying SNYK URL: {search_url}")
                    async with self.session.get(search_url, headers=headers, timeout=self.timeout) as response:
                        if response.status == 200:
                            html_content = await response.text()
                            found_vulns = self._parse_snyk_html(html_content, package_name)
                            vulnerabilities.extend(found_vulns)
                            self.logger.debug(f"Found {len(found_vulns)} vulnerabilities from {search_url}")
                            
                            # If we found vulnerabilities, we can stop trying other URLs
                            if found_vulns:
                                break
                        else:
                            self.logger.debug(f"SNYK request to {search_url} failed with status {response.status}")
                            
                except Exception as e:
                    self.logger.debug(f"Error with SNYK URL {search_url}: {e}")
                    continue
            
            # Remove duplicates
            unique_vulnerabilities = []
            seen_ids = set()
            for vuln in vulnerabilities:
                vuln_id = vuln.get('id') or vuln.get('title', '')
                if vuln_id and vuln_id not in seen_ids:
                    seen_ids.add(vuln_id)
                    unique_vulnerabilities.append(vuln)
            
            return unique_vulnerabilities
            
        except Exception as e:
            self.logger.debug(f"Error fetching SNYK vulnerabilities for {package_name}: {e}")
            return []
    
    def _parse_snyk_html(self, html_content: str, package_name: str) -> List[Dict]:
        """Parse SNYK HTML to extract vulnerability information"""
        vulnerabilities = []
        try:
            from bs4 import BeautifulSoup
            import re
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Look for vulnerability cards/items in SNYK HTML
            # SNYK typically shows vulnerabilities in structured sections
            vuln_sections = soup.find_all(['div', 'article', 'section'], class_=re.compile(r'vuln|vulnerability|issue'))
            
            # Also look for table rows that might contain vulnerability data
            vuln_rows = soup.find_all('tr')
            
            # Process vulnerability sections
            for section in vuln_sections:
                vuln_data = self._extract_vuln_from_section(section, package_name)
                if vuln_data:
                    vulnerabilities.append(vuln_data)
            
            # Process table rows for vulnerability data
            for row in vuln_rows:
                vuln_data = self._extract_vuln_from_row(row, package_name)
                if vuln_data:
                    vulnerabilities.append(vuln_data)
            
            # If no structured data found, try to extract from text patterns
            if not vulnerabilities:
                vulnerabilities = self._extract_vuln_from_text(html_content, package_name)
            
            # If still no vulnerabilities, try a more aggressive approach to find any vulnerability indicators
            if not vulnerabilities:
                vulnerabilities = self._extract_vuln_fallback(html_content, package_name)
            
            # Remove duplicates based on CVE ID or title
            seen_ids = set()
            unique_vulnerabilities = []
            for vuln in vulnerabilities:
                vuln_id = vuln.get('id') or vuln.get('title', '')
                if vuln_id and vuln_id not in seen_ids:
                    seen_ids.add(vuln_id)
                    unique_vulnerabilities.append(vuln)
            
            self.logger.debug(f"Parsed {len(unique_vulnerabilities)} unique vulnerabilities from SNYK HTML for {package_name}")
            return unique_vulnerabilities
            
        except ImportError:
            self.logger.warning("BeautifulSoup not available for SNYK HTML parsing. Install with: pip install beautifulsoup4")
            return []
        except Exception as e:
            self.logger.debug(f"Error parsing SNYK HTML for {package_name}: {e}")
            return []
    
    def _extract_vuln_from_section(self, section, package_name: str) -> Optional[Dict]:
        """Extract vulnerability data from a HTML section"""
        try:
            import re
            section_text = section.get_text()
            
            # Look for CVE IDs
            cve_pattern = re.compile(r'CVE-\d{4}-\d{4,}')
            cve_matches = cve_pattern.findall(section_text)
            
            # Look for SNYK IDs
            snyk_pattern = re.compile(r'SNYK-[A-Z]+-[A-Z0-9]+-\d+')
            snyk_matches = snyk_pattern.findall(section_text)
            
            # Only proceed if we found actual vulnerability IDs
            if not (cve_matches or snyk_matches):
                return None
            
            # STRICT: Require package name to be explicitly mentioned in vulnerability context
            package_lower = package_name.lower()
            if package_lower not in section_text.lower():
                self.logger.debug(f"Package {package_name} not mentioned in vulnerability section - skipping")
                return None
            
            # STRICT: Check for package-specific vulnerability indicators
            package_vuln_indicators = [
                f'{package_lower}.*vulnerability',
                f'vulnerability.*{package_lower}',
                f'{package_lower}.*affected',
                f'affected.*{package_lower}',
                f'{package_lower}.*CVE-\d{{4}}-\d{{4,}}',
                f'CVE-\d{{4}}-\d{{4,}}.*{package_lower}',
                f'{package_lower}.*SNYK-[A-Z]+-[A-Z0-9]+-\d+'
            ]
            
            has_package_context = any(
                re.search(pattern, section_text, re.IGNORECASE)
                for pattern in package_vuln_indicators
            )
            
            if not has_package_context:
                self.logger.debug(f"No package-specific vulnerability context found for {package_name} - skipping")
                return None
            
            # Look for severity
            severity_pattern = re.compile(r'(Critical|High|Medium|Low)', re.IGNORECASE)
            severity_matches = severity_pattern.findall(section_text)
            
            # Look for affected versions 
            version_pattern = re.compile(r'[<>=!]+\s*\d+\.\d+[.\d]*|[\[\(][\d\.,\s<>=!]*[\]\)]')
            version_matches = version_pattern.findall(section_text)
            
            vuln_id = snyk_matches[0] if snyk_matches else cve_matches[0]
            
            return {
                'id': vuln_id,
                'title': f"Vulnerability {vuln_id} in {package_name}",
                'severity': severity_matches[0].upper() if severity_matches else 'MEDIUM',
                'related_cves': cve_matches,
                'affected_versions': version_matches,
                'published_date': '',
                'description': section_text[:200].strip()
            }
            
        except Exception as e:
            self.logger.debug(f"Error extracting vulnerability from section: {e}")
        return None
    
    def _extract_vuln_from_row(self, row, package_name: str) -> Optional[Dict]:
        """Extract vulnerability data from a table row"""
        try:
            import re
            cells = row.find_all(['td', 'th'])
            if len(cells) < 2:
                return None
            
            row_text = ' '.join([cell.get_text() for cell in cells])
            package_lower = package_name.lower()
            
            # Look for CVE pattern in row
            cve_pattern = re.compile(r'CVE-\d{4}-\d{4,}')
            cve_matches = cve_pattern.findall(row_text)
            
            # Look for SNYK pattern in row
            snyk_pattern = re.compile(r'SNYK-[A-Z]+-[A-Z0-9]+-\d+')
            snyk_matches = snyk_pattern.findall(row_text)
            
            # Only proceed if we found vulnerability IDs
            if not (cve_matches or snyk_matches):
                return None
            
            # STRICT: Require package name AND vulnerability context
            vuln_context = ('vuln' in row_text.lower() or 'cve' in row_text.lower() or 'snyk' in row_text.lower())
            package_mentioned = package_lower in row_text.lower()
            
            if not (vuln_context and package_mentioned):
                self.logger.debug(f"Insufficient context for {package_name} in table row - skipping")
                return None
            
            # Look for severity in row
            severity_pattern = re.compile(r'(Critical|High|Medium|Low)', re.IGNORECASE)
            severity_matches = severity_pattern.findall(row_text)
            
            # Look for version information
            version_pattern = re.compile(r'[<>=!]+\s*\d+\.\d+[.\d]*')
            version_matches = version_pattern.findall(row_text)
            
            vuln_id = snyk_matches[0] if snyk_matches else cve_matches[0]
            
            return {
                'id': vuln_id,
                'title': f"Vulnerability {vuln_id} in {package_name}",
                'severity': severity_matches[0].upper() if severity_matches else 'MEDIUM',
                'related_cves': cve_matches,
                'affected_versions': version_matches,
                'published_date': '',
                'description': row_text[:200].strip()
            }
            
        except Exception as e:
            self.logger.debug(f"Error extracting vulnerability from row: {e}")
        return None
    
    def _extract_vuln_from_text(self, html_content: str, package_name: str) -> List[Dict]:
        """Extract vulnerabilities from plain text patterns - enhanced for JavaScript-heavy pages"""
        vulnerabilities = []
        try:
            import re
            
            # For JavaScript-heavy pages like SNYK, look for SNYK patterns directly in HTML
            # Look for SNYK patterns (enhanced pattern for SNYK format)
            snyk_pattern = re.compile(r'SNYK-[A-Z]+-[A-Z0-9]+-\d+')
            snyk_matches = snyk_pattern.findall(html_content)
            
            # Look for severity information nearby SNYK IDs
            severity_patterns = {
                'CRITICAL': re.compile(r'critical', re.IGNORECASE),
                'HIGH': re.compile(r'high', re.IGNORECASE),
                'MEDIUM': re.compile(r'medium', re.IGNORECASE),
                'LOW': re.compile(r'low', re.IGNORECASE)
            }
            
            # SNYK pages don't contain CVE information on the main package page
            # CVEs are only available on individual vulnerability pages, which would require
            # separate requests and significantly slow down scanning. Since NIST NVD and 
            # MITRE CVE databases already provide comprehensive CVE information, we focus
            # on SNYK-specific vulnerability identification here.
            
            # Create vulnerability entries ONLY for SNYK IDs that are package-specific
            package_lower = package_name.lower()
            for snyk_id in set(snyk_matches):
                # STRICT: Verify this SNYK ID is related to our specific package
                snyk_context_window = self._get_context_window(html_content, snyk_id, 1000)
                
                # Check if package name appears near this SNYK ID
                if package_lower not in snyk_context_window.lower():
                    self.logger.debug(f"SNYK ID {snyk_id} not related to package {package_name} - skipping")
                    continue
                
                # Additional validation: ensure it's a Python/pip package
                python_indicators = ['python', 'pip', 'pypi', 'py', package_lower]
                has_python_context = any(indicator in snyk_context_window.lower() for indicator in python_indicators)
                
                if not has_python_context:
                    self.logger.debug(f"SNYK ID {snyk_id} lacks Python package context for {package_name} - skipping")
                    continue
                
                # Try to find severity for this SNYK ID
                severity = self._extract_nearby_severity(html_content, snyk_id, severity_patterns)
                
                vulnerabilities.append({
                    'id': snyk_id,
                    'title': f"SNYK vulnerability {snyk_id} in {package_name}",
                    'severity': severity,
                    'related_cves': [],  # SNYK main page doesn't contain CVE info
                    'affected_versions': self._extract_version_info_near_pattern(html_content, snyk_id),
                    'published_date': '',
                    'description': f"SNYK vulnerability {snyk_id} found for {package_name} with package context"
                })
            
            self.logger.debug(f"Extracted {len(vulnerabilities)} vulnerabilities from HTML text patterns for {package_name}")
            
        except Exception as e:
            self.logger.debug(f"Error extracting vulnerabilities from text: {e}")
        
        return vulnerabilities
    
    def _get_context_window(self, html_content: str, pattern: str, window_size: int = 1000) -> str:
        """Get a context window around a pattern in HTML content"""
        try:
            pattern_pos = html_content.find(pattern)
            if pattern_pos == -1:
                return ""
            
            window_start = max(0, pattern_pos - window_size // 2)
            window_end = min(len(html_content), pattern_pos + window_size // 2)
            return html_content[window_start:window_end]
        except Exception:
            return ""
    
    def _extract_nearby_severity(self, html_content: str, pattern: str, severity_patterns: dict) -> str:
        """Extract severity information near a given pattern"""
        try:
            # Find the position of the pattern
            pattern_pos = html_content.find(pattern)
            if pattern_pos == -1:
                return 'MEDIUM'  # Default severity
            
            # Look in a window around the pattern (¬±500 characters)
            window_start = max(0, pattern_pos - 500)
            window_end = min(len(html_content), pattern_pos + 500)
            window_text = html_content[window_start:window_end]
            
            # Check for severity keywords in order of priority
            for severity, regex in [('CRITICAL', severity_patterns['CRITICAL']), 
                                   ('HIGH', severity_patterns['HIGH']),
                                   ('MEDIUM', severity_patterns['MEDIUM']), 
                                   ('LOW', severity_patterns['LOW'])]:
                if regex.search(window_text):
                    return severity
            
            return 'MEDIUM'  # Default if no severity found
        except Exception:
            return 'MEDIUM'
    
    
    def _extract_version_info_near_pattern(self, html_content: str, pattern: str) -> List[str]:
        """Extract version information near a given pattern"""
        try:
            import re
            pattern_pos = html_content.find(pattern)
            if pattern_pos == -1:
                return []
            
            # Look in a window around the pattern
            window_start = max(0, pattern_pos - 800)
            window_end = min(len(html_content), pattern_pos + 800)
            window_text = html_content[window_start:window_end]
            
            # Look for version patterns
            version_patterns = [
                r'[<>=!]+\s*\d+\.\d+[.\d]*',  # >= 1.2.3, < 2.0.0
                r'[\[\(][\d\.,\s<>=!]*[\]\)]',  # [1.0.0,2.0.0)
                r'versions?\s*[<>=!]+\s*\d+\.\d+[.\d]*',  # versions >= 1.0.0
                r'affects?\s*[:\s]*[<>=!]*\d+\.\d+[.\d]*'  # affects: 1.0.0
            ]
            
            version_info = []
            for pattern_regex in version_patterns:
                matches = re.findall(pattern_regex, window_text, re.IGNORECASE)
                version_info.extend(matches)
            
            return list(set(version_info))[:5]  # Limit to 5 version constraints
        except Exception:
            return []
    
    def _extract_vuln_fallback(self, html_content: str, package_name: str) -> List[Dict]:
        """Fallback method to detect vulnerabilities using strict patterns - only for legitimate vulnerabilities"""
        vulnerabilities = []
        try:
            import re
            
            # MUCH MORE STRICT fallback detection - only create entries when we have concrete evidence
            # First, must find specific CVE or SNYK IDs in the content
            cve_pattern = re.compile(r'CVE-\d{4}-\d{4,}')
            snyk_pattern = re.compile(r'SNYK-[A-Z]+-[A-Z0-9]+-\d+')
            
            cve_matches = cve_pattern.findall(html_content)
            snyk_matches = snyk_pattern.findall(html_content)
            
            # Only proceed if we found actual CVE or SNYK IDs
            if not cve_matches and not snyk_matches:
                self.logger.debug(f"No CVE or SNYK IDs found for {package_name} - no fallback vulnerabilities created")
                return []
            
            # Second, require specific package-related vulnerability context
            package_specific_indicators = [
                f'{package_name}.*vulnerability',
                f'vulnerability.*{package_name}',
                f'{package_name}.*CVE-\d{{4}}-\d{{4,}}',
                f'CVE-\d{{4}}-\d{{4,}}.*{package_name}',
                f'{package_name}.*SNYK-[A-Z]+-[A-Z0-9]+-\d+',
                f'SNYK-[A-Z]+-[A-Z0-9]+-\d+.*{package_name}',
                f'affected.*{package_name}',
                f'{package_name}.*affected'
            ]
            
            package_context_found = False
            for pattern in package_specific_indicators:
                if re.search(pattern, html_content, re.IGNORECASE):
                    package_context_found = True
                    self.logger.debug(f"Found package-specific vulnerability context: {pattern}")
                    break
            
            # Third, exclude false positive scenarios
            false_positive_indicators = [
                f'no vulnerabilities.*{package_name}',
                f'{package_name}.*no vulnerabilities',
                f'clean.*{package_name}',
                f'{package_name}.*clean',
                f'secure.*{package_name}',
                f'{package_name}.*secure',
                'no known vulnerabilities',
                'no security issues',
                'package not found',
                'no results found'
            ]
            
            has_false_positive_indicators = any(
                re.search(pattern, html_content, re.IGNORECASE) 
                for pattern in false_positive_indicators
            )
            
            # Only create vulnerability if we have IDs, package context, and no false positive indicators
            if package_context_found and not has_false_positive_indicators:
                # Look for severity indicators
                severity = 'MEDIUM'  # Default
                if re.search(r'critical', html_content, re.IGNORECASE):
                    severity = 'CRITICAL'
                elif re.search(r'high', html_content, re.IGNORECASE):
                    severity = 'HIGH'
                elif re.search(r'low', html_content, re.IGNORECASE):
                    severity = 'LOW'
                
                # Create vulnerability entry only for legitimate IDs
                if snyk_matches:
                    vuln_id = snyk_matches[0]
                elif cve_matches:
                    vuln_id = cve_matches[0]
                else:
                    # Should not reach here due to earlier check, but safety fallback
                    return []
                
                vulnerabilities.append({
                    'id': vuln_id,
                    'title': f"Vulnerability {vuln_id} in {package_name}",
                    'severity': severity,
                    'related_cves': cve_matches,
                    'affected_versions': [],
                    'published_date': '',
                    'description': f"Vulnerability {vuln_id} found for {package_name} with package-specific context"
                })
                
                self.logger.debug(f"Strict fallback detection found legitimate vulnerability {vuln_id} for {package_name}")
            else:
                self.logger.debug(f"Fallback detection criteria not met for {package_name} - no vulnerabilities created")
            
        except Exception as e:
            self.logger.debug(f"Error in fallback vulnerability detection: {e}")
        
        return vulnerabilities
    
    def _parse_snyk_interval_notation(self, current_version: str, 
                                    affected_ranges: List[str]) -> bool:
        """Parse SNYK interval notation like [,3.7.2), [1.0.0,2.0.0)"""
        if not current_version or not affected_ranges:
            return False
            
        try:
            from packaging import version
            current_ver = version.parse(current_version)
            
            for range_str in affected_ranges:
                if self._version_in_snyk_interval(current_ver, range_str):
                    return True
                    
        except Exception as e:
            self.logger.debug(f"Error parsing SNYK interval: {e}")
            
        return False
    
    def _version_in_snyk_interval(self, current_ver, interval: str) -> bool:
        """Check if version is in SNYK interval notation range"""
        try:
            from packaging import version
            
            # Parse interval notation like "[1.0.0,2.0.0)" or "[,3.7.2)"
            if ',' in interval:
                # Remove brackets and split
                cleaned = interval.strip('[]()').split(',')
                start_ver = cleaned[0].strip() if cleaned[0].strip() else None
                end_ver = cleaned[1].strip() if len(cleaned) > 1 and cleaned[1].strip() else None
                
                # Check start bound (always inclusive in SNYK notation)
                if start_ver and current_ver < version.parse(start_ver):
                    return False
                
                # Check end bound (usually exclusive in SNYK notation)
                if end_ver:
                    if interval.endswith(')'):  # Exclusive end
                        if current_ver >= version.parse(end_ver):
                            return False
                    elif interval.endswith(']'):  # Inclusive end
                        if current_ver > version.parse(end_ver):
                            return False
                
                return True
                
        except Exception:
            return False
            
        return False
    
    def _generate_nist_summary(self, results: List[Dict], current_version: str, 
                              affected_by_version: bool, package_name: str,
                              version_check_indeterminate: bool = False) -> str:
        """Generate NIST NVD-specific summary with enhanced version checking logic"""
        if current_version == "NEW":
            if results:
                cve_list = [r['cve_id'] for r in results[:15]]
                if len(results) > 15:
                    cve_list.append(f"... and {len(results)-15} more")
                return f"NEW package - Found {len(results)} CVE records: {', '.join(cve_list)}"
            else:
                return "NEW package - No CVE records found"
        else:
            if affected_by_version:
                affected_cves = [r for r in results if r.get('version_affected')]
                highest_severity = self._get_highest_severity([r['severity'] for r in affected_cves])
                return f"VULNERABLE - {len(affected_cves)} CVEs affect v{current_version} (Highest: {highest_severity})"
            elif results:
                # Check if we have indeterminate version checking for any CVEs
                indeterminate_cves = [r for r in results if r.get('version_check_indeterminate', False)]
                if indeterminate_cves and version_check_indeterminate:
                    # Only require manual review if there are 10 or more CVEs
                    if len(results) >= 10:
                        return f"Manual review required - {len(results)} CVEs found, {len(indeterminate_cves)} require manual version checking for v{current_version}"
                    else:
                        # For < 10 CVEs, default to SAFE to avoid unnecessary manual review
                        return f"SAFE - {len(results)} CVEs found but v{current_version} not affected (version checking uncertain for {len(indeterminate_cves)} CVEs)"
                else:
                    return f"SAFE - {len(results)} CVEs found but v{current_version} not affected"
            else:
                return "None found"
    
    def _generate_mitre_summary(self, results: List[Dict], current_version: str, 
                               affected_by_version: bool, package_name: str, 
                               version_check_indeterminate: bool = False) -> str:
        """Generate MITRE CVE-specific summary with enhanced version checking logic"""
        if current_version == "NEW":
            if results:
                cve_list = [r['cve_id'] for r in results[:15]]
                if len(results) > 15:
                    cve_list.append(f"... and {len(results)-15} more")
                return f"NEW package - Found {len(results)} MITRE CVE records: {', '.join(cve_list)}"
            else:
                return "NEW package - No MITRE CVE records found"
        else:
            if affected_by_version:
                affected_cves = [r for r in results if r.get('version_affected')]
                highest_severity = self._get_highest_severity([r['severity'] for r in affected_cves])
                return f"VULNERABLE - {len(affected_cves)} MITRE CVEs affect v{current_version} (Highest: {highest_severity})"
            elif results:
                # Check if we have indeterminate version checking for any CVEs
                indeterminate_cves = [r for r in results if r.get('version_check_indeterminate', False)]
                if indeterminate_cves and version_check_indeterminate:
                    # Only require manual review if there are 10 or more CVEs
                    if len(results) >= 10:
                        return f"Manual review required - {len(results)} MITRE CVEs found, {len(indeterminate_cves)} require manual version checking for v{current_version}"
                    else:
                        # For < 10 CVEs, default to SAFE to avoid unnecessary manual review
                        return f"SAFE - {len(results)} MITRE CVEs found but v{current_version} not affected (version checking uncertain for {len(indeterminate_cves)} CVEs)"
                else:
                    return f"SAFE - {len(results)} MITRE CVEs found but v{current_version} not affected"
            else:
                return "None found"
    
    def _generate_snyk_summary(self, results: List[Dict], current_version: str, 
                              affected_by_version: bool, package_name: str) -> str:
        """Generate SNYK-specific summary with enhanced CVE listing"""
        if current_version == "NEW":
            if results:
                # For NEW packages, list all found SNYK vulnerability IDs
                all_snyk_ids = []
                
                for result in results:
                    # Collect SNYK IDs
                    vuln_id = result.get('id', '')
                    if vuln_id.startswith('SNYK-'):
                        all_snyk_ids.append(vuln_id)
                
                # Remove duplicates and sort
                unique_snyk_ids = sorted(list(set(all_snyk_ids)))
                
                # Create summary listing all SNYK IDs
                if unique_snyk_ids:
                    if len(unique_snyk_ids) <= 10:
                        return f"NEW package - Found {len(results)} SNYK vulnerabilities: {', '.join(unique_snyk_ids)}"
                    else:
                        return f"NEW package - Found {len(results)} SNYK vulnerabilities: {', '.join(unique_snyk_ids[:10])} ... and {len(unique_snyk_ids)-10} more"
                else:
                    return f"NEW package - Found {len(results)} SNYK vulnerabilities"
            else:
                return "NEW package - No SNYK vulnerabilities found"
        else:
            # For existing packages, aggregate version information and match against current version
            if results:
                # Collect all affected version ranges found
                all_version_ranges = []
                affected_vulns = []
                
                for result in results:
                    affected_versions = result.get('affected_versions', [])
                    if isinstance(affected_versions, list):
                        all_version_ranges.extend(affected_versions)
                    elif isinstance(affected_versions, str) and affected_versions:
                        all_version_ranges.append(affected_versions)
                    
                    if result.get('version_affected', False):
                        affected_vulns.append(result)
                
                # Sum up version information
                version_summary = f"Found {len(results)} vulnerabilities with {len(all_version_ranges)} version constraints"
                
                if affected_by_version and affected_vulns:
                    # Current version is affected
                    highest_severity = self._get_highest_severity([r['severity'] for r in affected_vulns])
                    return f"VULNERABLE - {len(affected_vulns)} SNYK vulnerabilities affect v{current_version} (Highest: {highest_severity})"
                elif results:
                    # Vulnerabilities found but current version not affected
                    return f"SAFE - {len(results)} SNYK vulnerabilities found but v{current_version} not affected"
                else:
                    return "None found"
            else:
                return "None found"

    async def close(self):
        """Close async session"""
        if self.session:
            await self.session.close()
            self.session = None


class SynchronousVulnerabilityScanner:
    """Synchronous wrapper for vulnerability scanning"""
    
    def __init__(self, timeout: int = 30, max_retries: int = 3, openai_api_key: Optional[str] = None,
                 azure_endpoint: Optional[str] = None, azure_model: str = "gpt-4o-mini"):
        self.scanner = VulnerabilityScanner(
            timeout, max_retries, 
            openai_api_key=openai_api_key,
            azure_endpoint=azure_endpoint,
            azure_model=azure_model
        )
    
    def scan_package(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Synchronous scan of a single package"""
        return asyncio.run(self.scanner.scan_all_databases(package_name, github_url, current_version))
    
    def scan_packages(self, package_names: List[str]) -> Dict[str, Dict[str, Any]]:
        """Synchronous scan of multiple packages"""
        results = {}
        for package_name in package_names:
            results[package_name] = self.scan_package(package_name)
        return results
    
    def close(self):
        """Close scanner"""
        asyncio.run(self.scanner.close())